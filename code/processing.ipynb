{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CVS from Violations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:** Please note that some parts of the code in this Jupyter Notebook cannot be run due to the fact that the required data has not been anonymized and is therefore not publicly available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define method that returns all violation files in `data/student-violations/<directory>` into one list**\n",
    "\n",
    "It required a specific format for the directory, \\<directory\\>/task-x/student-task-x.json\n",
    "\n",
    "Three directories currently follow this format:\n",
    "\n",
    "- `violations-pmd` (inda rules are used)\n",
    "- `violations-full-pmd` (all pmd rules are used)\n",
    "- `violations-sorald` (all sorald rules are used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_violation_files(dir):\n",
    "    student_files = []\n",
    "    tasks = [ (f.path,f.name) for f in os.scandir(dir) if f.is_dir() ] #Get all task folders \"task-x\"\n",
    "    for t in tasks:\n",
    "        task = t[1]\n",
    "        json_files = [ (task,f.path,f.name,f.name.split('-')[0]) for f in os.scandir(t[0]) if f.is_file() ] # (task,path,filename,student)\n",
    "        student_files = student_files + json_files\n",
    "    return student_files\n",
    "\n",
    "def get_violation_files_template(dir):\n",
    "    student_files = []\n",
    "    tasks = [ (f.path,f.name) for f in os.scandir(dir) if f.is_dir() ]\n",
    "    for t in tasks:\n",
    "        task = t[1]\n",
    "        json_files = [ (task,f.path,f.name,f.name.split('-')[0]) for f in os.scandir(t[0]) if f.is_file() ] # (task,path,filename,student)\n",
    "        student_files = student_files + json_files\n",
    "    return student_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define methods that returns list of actually used rules in both PMD and sorald**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scans the inda.xml ruleset and extracts all rules used.\n",
    "\n",
    "def get_pmd_rules():\n",
    "    all_rules = []\n",
    "    with open(\"../rulesets/inda.xml\", 'r') as f:\n",
    "        data = f.read()\n",
    "        Bs_data = BeautifulSoup(data, \"xml\")\n",
    "        b_rules = Bs_data.find_all('rule')\n",
    "        refs = [r['ref'] for r in b_rules ]\n",
    "\n",
    "        all_rules = [re.search('.*\\.xml/(.*)', r).group(1) for r in refs]\n",
    "    return all_rules\n",
    "\n",
    "# All sorald rules are defined in a dictionary [Key: ruleKey Value: ruleName] saved as binary file.\n",
    "\n",
    "def get_sorald_rules():\n",
    "    with open('../rulesets/sorald-rules.bin','rb') as infile:\n",
    "        return pickle.load(infile)\n",
    "\n",
    "# Rules used for sorald, outdated\n",
    "def accepted_rules():\n",
    "     return ['S125','S3972','S2583','S1871','S1120','S121','S122','S2208','S126','S109','S5261','S1751','S4144']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load and return dictionaries containing information about three different things**\n",
    "\n",
    "- `year_student_ta` : For each year what ta and difficulty does each student have? {'year' : {'student' : (TA,difficulty)}}\n",
    "- `year_repo_status` : For each year what is the status for each repository (has student pushed? recieved pass?) **Not used anymore**\n",
    "- `year_student_lines` : For each year what lines in a specific file has a student modified or created? {'year' : {'task' : {'student': {'file' : \\[lines\\]}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information_dictionaries():\n",
    "    year_student_ta = {}\n",
    "    year_student_lines = {}\n",
    "    years=[\"2021\",\"2020\",\"2019\",\"2018\"]\n",
    "\n",
    "    for year in years:\n",
    "        infile = open(f'data/groups-data/student-groups{year}.bin', 'rb') # Not available\n",
    "        year_student_ta[year] = pickle.load(infile)\n",
    "        infile.close()\n",
    "\n",
    "\n",
    "        infile = open(f'data/student-lines/student-lines-{year}.bin', 'rb') # Not available\n",
    "        year_student_lines[year] = pickle.load(infile)\n",
    "        infile.close()\n",
    "    return year_student_ta,year_student_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define method in charge of analyzing violation-files**\n",
    "\n",
    "Based on `path_to_stats_file` read the json-file and retrieve the number of occurences for each violation\n",
    "\n",
    "**Note:** Method for sorald required extra check to remove violations found in Test-files as it doesn't offer functionality to easily exclude those files from being analyzed.\n",
    "\n",
    "**New:** Each method also only counts number of rows (excluding Test-files) modified/created by student (using `year_student_lines`) and what violations a student is responsible for (also using `year_student_lines`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_violations_pmd(path_to_stats_file: str,task,student,file_name,year,year_student_lines):\n",
    "    number_of_violation = {}\n",
    "    number_of_violation_old = {}\n",
    "    key_error = 0\n",
    "    \n",
    "    if file_name == f\"{student}-task-19\" or file_name == f\"{student}-week-19\":\n",
    "        file_name = f\"{student}-quicksort\"\n",
    "\n",
    "    lines_files = year_student_lines[year][task][student] # Get dictionary Key: File Value: List of lines modified/created by student\n",
    "    loc = 0\n",
    "    error_files = []\n",
    "    good_files = 0\n",
    "    with open(path_to_stats_file) as stats_file:\n",
    "        json_object = json.loads(stats_file.read())\n",
    "        files = json_object[\"files\"]\n",
    "        \n",
    "        # If PMD was unsuccessful with analyzing repo, return \"ok\" as False and standard values for rest (will be ignored).\n",
    "        errors = json_object[\"processingErrors\"]\n",
    "        if len(errors) > 0:\n",
    "            pattern = f\".*{file_name}/(.*)\"\n",
    "            for f in errors:\n",
    "                key = re.search(pattern,f[\"filename\"]).group(1) #Gets the file name analyzed by PMD\n",
    "                if key in lines_files: # Requirement that the file is actually in lines_files (found when running git blame) \n",
    "                    lines = lines_files[key]\n",
    "                    error_files.append((task,student,key))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for f in files:\n",
    "            \n",
    "            pattern = f\".*{file_name}/(.*)\"\n",
    "            key = re.search(pattern,f[\"filename\"]).group(1) #Gets the file name analyzed by PMD\n",
    "            \n",
    "\n",
    "            violations = f[\"violations\"]\n",
    "            \n",
    "            # Count number of violations without regards if student is responsible\n",
    "            for v in violations:\n",
    "                number_of_violation_old[v[\"rule\"]] = number_of_violation_old.get(v[\"rule\"],0) + 1\n",
    "            \n",
    "            if key in lines_files: # Requirement that the file is actually in lines_files (found when running git blame) \n",
    "                lines = lines_files[key] # Get lines student modified in this file this task\n",
    "                if(len(lines) > 0):\n",
    "                    good_files += 1\n",
    "                for v in violations:\n",
    "                    line = v[\"beginline\"]\n",
    "                    if str(line) in lines: # Check if violation is on line student wrote\n",
    "                        number_of_violation[v[\"rule\"]] = number_of_violation.get(v[\"rule\"],0) + 1\n",
    "            else:\n",
    "                key_error +=1\n",
    "        \n",
    "        return True,number_of_violation,len(files),key_error,number_of_violation_old,error_files,good_files\n",
    "    \n",
    "\n",
    "def get_number_of_violations_sorald(path_to_stats_file: str,student,task,year,year_student_lines,skipped_files):\n",
    "    number_of_violation = {}\n",
    "    number_of_violation_old = {}\n",
    "    \n",
    "    lines_files = year_student_lines[year][task][student]\n",
    "    loc = lines_files[\"loc\"]\n",
    "    with open(path_to_stats_file) as stats_file:\n",
    "        json_object = json.loads(stats_file.read())\n",
    "        mined_rules = json_object[\"minedRules\"]\n",
    "        \n",
    "        for violation in mined_rules:\n",
    "            occurr = 0\n",
    "            occur_old = 0\n",
    "            for location in violation[\"warningLocations\"]:\n",
    "                path = location[\"filePath\"]\n",
    "                if (task,student,path) in skipped_files:\n",
    "                    continue\n",
    "                line = location[\"startLine\"]\n",
    "                \n",
    "                match = re.search('.*Test.java',path) #Exclude violations found in test-files\n",
    "                if match is None and path in lines_files:\n",
    "                    \n",
    "                    if str(line) in lines_files[path]:\n",
    "                        occurr += 1\n",
    "                    occur_old += 1\n",
    "            number_of_violation_old[violation[\"ruleKey\"]] = occur_old\n",
    "            number_of_violation[violation[\"ruleKey\"]] = occurr\n",
    "        return number_of_violation,number_of_violation_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define method extracting data from json files**\n",
    "\n",
    "**Note:** The current functionality excludes repos from Sorald which could not be analyzed by PMD, this is because Sorald works for all while PMD does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc(student,task,error_files,year_student_lines,year):\n",
    "    loc_in_files = year_student_lines[year][task][student][\"loc\"]\n",
    "    loc = 0\n",
    "    for file in loc_in_files:\n",
    "        if (task,student,file) in error_files:\n",
    "            print(\"skipping: \" , (task,student,file))\n",
    "            continue\n",
    "        loc += year_student_lines[year][task][student][\"loc\"][file]\n",
    "    return loc\n",
    "\n",
    "def extract_json_pmd(csvwriter,student_files,all_rules,year,year_student_ta,year_student_lines):\n",
    "    success = 0\n",
    "    fails = 0\n",
    "    skipped = []\n",
    "    key_error_tot = 0\n",
    "    repos = []\n",
    "\n",
    "    pmd_errors = {}\n",
    "    for f in student_files:\n",
    "        task = f[0]\n",
    "        task_number = task.split('-')[1]\n",
    "        student = f[3]\n",
    "        repos.append((student,task))\n",
    "        ta = year_student_ta[year][student][0]\n",
    "        difficulty = year_student_ta[year][student][1]\n",
    "\n",
    "        if task_number not in pmd_errors:\n",
    "            pmd_errors[task_number] = {}\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        path = f[1]\n",
    "\n",
    "        ok,stats,num_files,key_error,stats_old,error_files,good_files = get_number_of_violations_pmd(path,task_number,student,f[2],year,year_student_lines)\n",
    "        total_files = good_files + len(error_files)\n",
    "        skipped = skipped + error_files\n",
    "        key_error_tot +=key_error\n",
    "        loc = get_loc(student,task_number,error_files,year_student_lines,year)\n",
    "        if ok: # and (status[0] or status[1]):\n",
    "            success+=1\n",
    "            for v in all_rules:\n",
    "                amount = stats.get(v,0)\n",
    "                \n",
    "                occurrence = 1 if amount > 0 else 0\n",
    "                row = [year,task_number,ta,difficulty,student,loc,v,'-','PMD',occurrence,amount,len(error_files),total_files]\n",
    "                pmd_errors[task_number][student] = len(error_files)\n",
    "                csvwriter.writerow(row)\n",
    "        else:\n",
    "\n",
    "            row = [year,task_number,ta,difficulty,student,-1,'ERROR','ERROR','ERROR',-1,-1,-1,-1]\n",
    "            csvwriter.writerow(row)\n",
    "                \n",
    "            fails += 1\n",
    "\n",
    "    print(\"pmd key error in status-lines:\", key_error_tot)\n",
    "    return success,fails,skipped,repos,pmd_errors\n",
    "\n",
    "\n",
    "def extract_json_sorald(csvwriter,student_files,all_rules,skipped_files,accepted_rules,year,year_student_ta,year_student_lines,pmd_errors):\n",
    "    success = 0\n",
    "    repos = []\n",
    "    for f in student_files:\n",
    "        task = f[0]\n",
    "        task_number = task.split('-')[1]\n",
    "        student = f[3]\n",
    "\n",
    "        \n",
    "        repos.append((student,task))\n",
    "        ta = year_student_ta[year][student][0]\n",
    "        difficulty = year_student_ta[year][student][1]\n",
    "        path = f[1]\n",
    "        stats,stats_old = get_number_of_violations_sorald(path,student,task_number,year,year_student_lines,skipped_files)\n",
    "        loc = get_loc(student,task_number,skipped_files,year_student_lines,year)\n",
    "\n",
    "        success += 1\n",
    "        for v in all_rules:\n",
    "            if accepted_rules is not None and v not in accepted_rules:\n",
    "                continue\n",
    "            name = all_rules[v]\n",
    "\n",
    "            \n",
    "            amount = stats.get(v,0)\n",
    "            amount_old = stats_old.get(v,0)\n",
    "            occurrence = 1 if amount > 0 else 0\n",
    "            pmd_error = pmd_errors[task_number][student]\n",
    "            row = [year,task_number,ta,difficulty,student,loc,name,v,'SonarSource',occurrence,amount,pmd_error,-1]\n",
    "            csvwriter.writerow(row)\n",
    "    return success,repos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create CVS file**\n",
    "\n",
    "The CVS file will have header: `'year','task','ta','difficulty','student','loc','violation','violation-id','tool','occur','amount','error-files','total-files'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2021\"\n",
    "path = \"data/processing-results\"\n",
    "with open(f\"{path}/student-data-{year}-exp.csv\", 'w+') as csvfile:\n",
    "    header2 = ['year','task','ta','difficulty','student','loc','violation','violation-id','tool','occur','amount','error-files','total-files']\n",
    "\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(header2)\n",
    "    year_student_ta,year_student_lines = get_information_dictionaries()\n",
    "    #PMD part\n",
    "    student_files = get_violation_files(f\"data/student-violations/violations-pmd/{year}\")\n",
    "    print(\"PMD stats files: \", len(student_files))\n",
    "    all_rules = get_pmd_rules()\n",
    "    success_pmd,fails_pmd,skipped,pmd_repos,pmd_errors = extract_json_pmd(csvwriter,student_files,all_rules,year,year_student_ta,year_student_lines)\n",
    "\n",
    "    #Sorald part\n",
    "    accepted_rules_sorald = accepted_rules()\n",
    "    student_files = get_violation_files(f\"data/student-violations/violations-sorald/{year}\")\n",
    "    all_rules = get_sorald_rules()\n",
    "    success_sorald,sorald_repos = extract_json_sorald(csvwriter,student_files,all_rules,skipped,accepted_rules_sorald,year,year_student_ta,year_student_lines,pmd_errors)\n",
    "\n",
    "not_same = 0\n",
    "for repo in pmd_repos:\n",
    "    if repo not in sorald_repos:\n",
    "        not_same += 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Apr 13 2022, 08:48:06) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
